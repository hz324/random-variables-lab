\documentclass[12pt]{article}
\textwidth 15.5cm \oddsidemargin 0cm \topmargin -1cm \textheight
24cm \footskip 1.5cm \usepackage{epsfig}
\usepackage{amsmath,graphicx,psfrag,pstcol,listings}
\def\n{\noindent}
\def\u{\underline}
\def\hs{\hspace}
\newcommand{\thrfor}{.^{\displaystyle .} .}
\newcommand{\bvec}[1]{{\bf #1}}

\begin{document}

\noindent
\rule{15.7cm}{0.5mm}


\begin{center}
{\bf ENGINEERING TRIPOS PART II A}
\end{center}
\vspace{0.5cm} {\bf EIETL \hfill MODULE EXPERIMENT 3F3}
\vspace{0.5cm}
\begin{center}
{\bf RANDOM VARIABLES AND RANDOM NUMBER GENERATION\\
Short  Report Template\\\hfill \\Name: Anran Jin \\\hfill\\
College: Jesus  \\\hfill
\\
Lab Group Number: N/A
}
\end{center}
\rule{15.7cm}{0.5mm}



\vspace*{1cm}
\begin{center}
\fbox{\parbox{0.8\linewidth}{\bf This  is a template suitable for the short report write-up. Simply edit the Latex or Word document to include your calculations/ results/ code.}}
\end{center}
\vspace*{1cm}

\begin{enumerate}
\item {\bf Uniform and normal random variables.}

Histogram of Gaussian random numbers overlaid on exact Gaussian curve (scaled):


\includegraphics[width=0.9\textwidth]{../pic/11Gaussian_hist.jpg}

\vspace{3in}

Histogram of Uniform random numbers overlaid on exact Uniform curve (scaled):

\includegraphics[width=0.9\textwidth]{../pic/12Uniform_hist.jpg}

\vspace{0.5cm}

Kernel density estimate for Gaussian random numbers overlaid on exact Gaussian curve:

\includegraphics[width=0.9\textwidth]{../pic/13Gaussian_ker.jpg}

\vspace{3in}

Kernel density estimate for Uniform random numbers overlaid on exact Uniform curve:

\includegraphics[width=0.9\textwidth]{../pic/14Uniform_ker.jpg}

\vspace{1cm}
  
Comment on the advantages and disadvantages of the kernel density method compared with the histogram method for estimation of a probability density from random samples:
\\\\
{\em
Histogram is relatively easy to calculate and program. However, it is quite rough an estimation given insufficient numbers of bins. Indeed, we are using discrete bars to represent continuous pdfs, and it cannot be so accurate.\\\\
Kernel density estimation is yet a smoothed version of histograms, and hence it gives better accuracy on representing continuous pdfs. However, especially when dealing with discrete pdfs or those with discontinuous jumps, the smoothing effect of kernel density estimation is a drawback since it will smooth where there should be a discontinuity, just like what we observed in plotting uniform distribution. In addition, kernel density is more difficult to calculate and program.\\
}

\vspace{3in}


Theoretical  mean and standard deviation calculation for uniform density as a function of $N$:
\\\\
{\em
Due to the multinomial distribution theory, the mean and standard variation are given as
\begin{math}
Np_j \text{ and } \sqrt{N(1-p_j)p_j}, 
\text{ where }  p_j \end{math} is the probability of a sample lies in bin j.
In the uniform case, \begin{math} p_j = 1/J \end{math}, where J is the total bin number.
Thus, the mean and standard variation are \begin{math} N/J \text{ and } \sqrt{N(J-1)/J^2} \end{math}.
}
\vspace{1in}


Explain behaviour as $N$ becomes large:
\\\\
{\em
As N increases, mean will increase accordingly. Although the absolute scale of standard variation does increase, its relative scale with respect to the mean will decrease since it is \begin{math}\sim \sqrt{N}/N = 1/\sqrt{N}\end{math}. This means that the histogram will fit the exact distribution curve better as N becomes large.
}
\vspace{2cm}



Plot of histograms for $N=100$,  $N=1000$ and $N=10000$ with theoretical mean  and $\pm 3$ standard deviation lines:
\\
\includegraphics[width=0.9\textwidth]{../pic/15Devi_line.jpg}

\vspace{3in}


 Are your histogram results consistent with the multinomial distribution theory? 
\\\\
{\em
The theoretical mean and standard variation are close to the experimented ones. However, they do not match exactly since these are probabilistic samples.
}
\vspace{2cm}


\item {\bf Functions of random variables}\\
For normally distributed ${\cal N}(x|0,1)$ random variables, take $y=f(x)=ax+b$. Calculate $p(y)$ using the Jacobian formula:
\\\\
{\em
Since the transformation is injective in this case, we refer to the formula:
\begin{equation*}
\begin{split}
  p(y)& = \left.\frac{p(x)}{|dy/dx|}\right|_{x=f^{-1}(y)} \\
      & = \left.\frac{N\left(x\middle|0,1\right)}{|a|}\right|_{x=\frac{y-b}{a}} \\
      & = \frac{1}{\sqrt{2\pi}|a|}\exp{(-\frac{(y-b)^2}{2a^2})}
\end{split}
\end{equation*}
}
\vspace{1cm}


Explain how this is linked to the general normal density with non-zero mean and non-unity variance:

{\em
Obviously, the transformed random variable obeys normal distribution with mean b and standard variation \begin{math} |a| \end{math}.\\
We can varify this in another way. Asssue the original random variable is X, then:\\\\
\begin{math}
E[aX+b] = aE[X] + b = b \\
Var[aX+b] = a^2Var[X] = a^2  
\end{math}
\\\\
This agrees with the previous Jacobian result.
}
\vspace{3in}

Verify this formula by transforming a large collection of random samples $x^{(i)}$ to give $y^{(i)}=f(x^{(i)})$, histogramming the resulting $y$ samples, and overlaying a plot of your formula calculated using the Jacobian:
\\
\includegraphics[width=0.9\textwidth]{../pic/21Linear.jpg}

\vspace{1cm}

Now take $p(x)={\cal N}(x|0,1)$ and $f(x)=x^2$. Calculate $p(y)$ using the Jacobian formula:\\
{\em
The transformation is not injective this time, and hence we need to consider every possible solutions:\\
\begin{equation*}
\begin{split}
  p(y) & = \sum_{k=1}^2{\left.\frac{p(x)}{|dy/dx|}\right|_{x=f^{-1}(y)}} \\
       & = \left.\frac{p(x)}{|2x|}\right|_{x=\sqrt{y}}+\left.\frac{p(x)}{|2x|}\right|_{x=-\sqrt{y}} \\
       & = \frac{p(\sqrt{y})}{|\sqrt{y}|}\\
       & = \frac{1}{\sqrt{2\pi y}}\exp{(-\frac{y}{2})}
\end{split}
\end{equation*}
}
\vspace{5in}




Verify your result by histogramming of transformed random samples:
\\
\includegraphics[width=0.9\textwidth]{../pic/22Quad.jpg}

\vspace{1in}


\item{\bf Inverse CDF method} 



Calculate the CDF and the inverse CDF for the exponential distribution: 
\\
{\em
\begin{equation*}
\begin{split}
  x = F(y) & = \int_0^y \mathrm \exp{(-t)} \mathrm dt \\
           & = 1 - exp(-y) , y\geq0. \\
   exp(-y) & = 1-x \\
   y & = -ln(1-x) \quad (0 \leq x < 1)        
\end{split}    
\end{equation*}   
}
\vspace{3in}



Matlab code for inverse CDF method for generating samples from the exponential distribution:
\\

{\em
\begin{lstlisting}[language=Octave]
uniform_samples = rand(1000,1); % uniform random samples
exp_samples = -log(1 - uniform_samples); %inverse CDF
\end{lstlisting}
}

\vspace{2cm}



Plot histograms/ kernel density estimates and overlay them on the desired exponential density:

\includegraphics[width=0.9\textwidth]{../pic/31CDF.jpg}

\vspace{3in}

\item {\bf Simulation from a `difficult'  density.}

Matlab code to generate $N$ random numbers drawn from the distribution of $X$:
\\
{\em
\begin{lstlisting}[language=Octave]
N = 10000;
U = -pi/2 + rand(N,1) * pi; % Uniform random samples
V = exprnd(1,N,1); % Exponential random samples
b = 1/alpha * atan(beta*tan(pi*alpha/2));
s = (1+beta^2 * (tan(pi*alpha/2))^2)^(1/(2*alpha));
X = s * sin(alpha*(U+b))./((cos(U)).^(1/alpha))
    .* ((cos(U-alpha*(U+b)))./V).^((1-alpha)/alpha);
\end{lstlisting}
}
\vspace{0.5cm}

Plot some histogram density estimates with $\alpha=0.5,\,1.5$ and several values of $\beta$:
\includegraphics[width=0.45\textwidth]{../pic/41half_nil.jpg}
\includegraphics[width=0.45\textwidth]{../pic/42one_nil.jpg}
\\
\includegraphics[width=0.45\textwidth]{../pic/43one_one.jpg}
\includegraphics[width=0.45\textwidth]{../pic/44one_negone.jpg}
\\
\includegraphics[width=0.45\textwidth]{../pic/46one_sev.jpg}
\includegraphics[width=0.45\textwidth]{../pic/45one_negsev.jpg}

\vspace{3in}

Hence comment on the interpretation of the parameters $\alpha$ and $\beta\in[-1,+1]$:
\\\\
{\em
Judging from the graphs obtained above, we can infer that \begin{math}\alpha\end{math} controls the slope of the pulse. The pulse will be steeper with a smaller \begin{math}\alpha\end{math}.\\\\
When \begin{math}\beta > 0\end{math}, it shapes only the negative half of the pulse. As \begin{math}\beta\end{math} goes larger, the slope of the negative half will be steeper, and when \begin{math}\beta = 1\end{math}, the pulse is almost like half-truncated. Similiar comments for negative \begin{math}\beta\end{math}.  
}

\end{enumerate}



\end{document}



\end{document}


